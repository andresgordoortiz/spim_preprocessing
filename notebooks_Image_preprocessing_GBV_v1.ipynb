{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cddaddd0-d81e-4667-b79b-539e4bce10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2026-01-15\n",
    "#This is an annotated version of Andres Navarrete Image_Preprocessing pipeline (version from 2025-12-22)\n",
    "#The pipeline was annotated by Guilherme Ventura using the Gemini AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c2342-11e0-4b21-a927-800ad03bf5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 1: System Memory Check change\n",
    "#This block ensures your machine has enough RAM to handle large 3D image stacks, which can often exceed several gigabytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ea200dd-8897-4260-a672-9f5eb24c06d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total (seen by this process) GB: 1023.8580017089844\n",
      "Available GB: 622.9937782287598\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "# Check system memory to avoid crashes during heavy image processing\n",
    "vm = psutil.virtual_memory()\n",
    "print(\"Total (seen by this process) GB:\", vm.total / (1024**3))\n",
    "print(\"Available GB:\", vm.available / (1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98debecb-7496-45bc-9064-e3c5dc416bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports & Library Configuration\n",
    "# This cell imports the necessary tools for image math (numpy), image IO (tifffile, pims),\n",
    "# and specialized microscopy algorithms(RedLionfishDeconv, WBNS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca8fcc8-881c-47b7-b061-e48c1dfe98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from WBNS import WBNS_image\n",
    "\n",
    "import RedLionfishDeconv as rl\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.transform import rescale, resize\n",
    "from nd2reader import ND2Reader\n",
    "import os\n",
    "import cv2\n",
    "import pims\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# Specialized microscopy tools\n",
    "from WBNS import WBNS_image             # Wavelet Background Noise Subtraction\n",
    "import RedLionfishDeconv as rl          # GPU-accelerated Richardson-Lucy Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcb74188-7fe5-4f81-8747-cb7e3874cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell 3: Image scaling using a linear constrast stretcher\n",
    "# In microscopy, images often come out \"flat\" or dim because the camera sensor didn't use its full dynamic range.\n",
    "# This part of the code forces the image to span from a minimum value (min_val) to a maximum value (max_val), typically 0 to 65535 for 16-bit images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a834027-a67f-4909-b1e2-7a2c1f55b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metada data tiff images\n",
    "def image_scaling_intens(img, min_val, max_val, print_res=False):\n",
    "\n",
    "    # start scaling\n",
    "    img_shape = img.shape\n",
    "    img_type = img.dtype\n",
    "    img_min = np.amin(img)\n",
    "    img_max = np.amax(img)\n",
    "\n",
    "    if img_shape[0] <  300:\n",
    "        img = np.reshape(img, newshape = -1)\n",
    "        img = cv2.normalize(img, None, alpha = min_val, beta = max_val, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "        img = np.reshape(img, newshape = img_shape)\n",
    "    else:\n",
    "        scale = img_max - img_min\n",
    "        new_scale = max_val - min_val\n",
    "        img = (new_scale * (img.astype(np.float32) - img_min) / scale) + min_val\n",
    "\n",
    "    img = img.astype(img_type.name)\n",
    "\n",
    "    if print_res == True:\n",
    "        newimg_min = np.amin(img)\n",
    "        newimg_max = np.amax(img)\n",
    "        print('     -Intensity Norm  from (%d , %d) to  (%d, %d) ' % (img_min, img_max, newimg_min, newimg_max))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b87320-2f39-49e9-9016-fa905639a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Reads the voxel size (so the physical size of our image in microns) from the tif file.\n",
    "# Remember that this needs to be input by the user!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aaabe7c-33b9-4bf5-82c8-076cca2c4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tiff_voxel_size(file_path):\n",
    "    \"\"\"\n",
    "    Extract voxel size from TIFF metadata\n",
    "    \"\"\"\n",
    "    def _xy_voxel_size(tags, key):\n",
    "        assert key in ['XResolution', 'YResolution']\n",
    "        if key in tags:\n",
    "            num_pixels, units = tags[key].value\n",
    "            return units / num_pixels\n",
    "        return 1.\n",
    "\n",
    "    with tifffile.TiffFile(file_path) as tiff:\n",
    "        image_metadata = tiff.imagej_metadata\n",
    "        if image_metadata is not None:\n",
    "            z = image_metadata.get('spacing', 1.)\n",
    "        else:\n",
    "            z = 1.\n",
    "\n",
    "        tags = tiff.pages[0].tags\n",
    "        y = _xy_voxel_size(tags, 'YResolution')\n",
    "        x = _xy_voxel_size(tags, 'XResolution')\n",
    "\n",
    "        return [x, y, z]\n",
    "\n",
    "\n",
    "def read_nd2_voxel_size(image):\n",
    "\n",
    "    md = image.metadata     # metadata object from nd2reader\n",
    "    # Pixel sizes in micrometers\n",
    "    x = md[\"pixel_microns\"]\n",
    "    y = md[\"pixel_microns\"]\n",
    "    z = 3.0\n",
    "\n",
    "    return [x, y, z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fe7b2c1-05e7-4679-bd2b-8957fe8f9020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5:\n",
    "# This cell corrects the loss of fluorescence intensity in depth in the SPIM images, and it normalizes the intensity across the z-stack\n",
    "# The code calculates a \"robust statistic\" for every single slice in your 3D stack.\n",
    "# It doesn't use the simple mean because one very bright spot could skew the results. Instead:\n",
    "# Method p95 (Default): It looks at the 95th percentile of pixels in each slice.\n",
    "# This essentially says, \"How bright are the actual objects in this slice, ignoring the dark background?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e7d744-57ec-4b79-ba9c-22591537b3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_intensity_correction(\n",
    "    stack: np.ndarray,\n",
    "    z_axis: int = 0,\n",
    "    method: str = \"p95\",          # \"median\", \"p90\", \"p95\", \"p99\"\n",
    "    smooth_window: int = 9,       # odd number; smoothing along z\n",
    "    eps: float = 1e-8,\n",
    "    preserve_dtype: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Multiplicative Z-intensity correction: rescales each z-slice so a chosen robust\n",
    "    statistic (e.g., p95) is constant along z. Good for depth attenuation / bleaching.\n",
    "\n",
    "    Returns corrected_stack, scale_factors (len = Z)\n",
    "    \"\"\"\n",
    "    if stack.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D stack, got {stack.shape}\")\n",
    "\n",
    "    x = np.moveaxis(stack, z_axis, 0).astype(np.float32, copy=False)  # (Z, Y, X)\n",
    "\n",
    "    # per-slice robust \"level\"\n",
    "    if method == \"median\":\n",
    "        levels = np.median(x.reshape(x.shape[0], -1), axis=1)\n",
    "    elif method.startswith(\"p\"):\n",
    "        q = float(method[1:])\n",
    "        levels = np.percentile(x.reshape(x.shape[0], -1), q, axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'median' or 'pXX' like 'p95'\")\n",
    "\n",
    "    # avoid crazy scaling if a slice is empty/dark\n",
    "    levels = np.maximum(levels, eps)\n",
    "\n",
    "    # smooth levels along z (simple moving average)\n",
    "    if smooth_window is not None and smooth_window > 1:\n",
    "        if smooth_window % 2 == 0:\n",
    "            smooth_window += 1\n",
    "        pad = smooth_window // 2\n",
    "        lvl_pad = np.pad(levels, (pad, pad), mode=\"edge\")\n",
    "        kernel = np.ones(smooth_window, dtype=np.float32) / smooth_window\n",
    "        levels_s = np.convolve(lvl_pad, kernel, mode=\"valid\")\n",
    "    else:\n",
    "        levels_s = levels\n",
    "\n",
    "    # target = median level (keeps overall scale similar)\n",
    "    target = np.median(levels_s)\n",
    "    scales = target / levels_s  # multiply each slice by scales[z]\n",
    "\n",
    "    y = x * scales[:, None, None]\n",
    "\n",
    "    y = np.moveaxis(y, 0, z_axis)\n",
    "\n",
    "    if not preserve_dtype:\n",
    "        return y.astype(np.float32, copy=False), scales\n",
    "\n",
    "    # convert back\n",
    "    if np.issubdtype(stack.dtype, np.integer):\n",
    "        info = np.iinfo(stack.dtype)\n",
    "        y = np.clip(y, info.min, info.max).astype(stack.dtype)\n",
    "    else:\n",
    "        y = y.astype(stack.dtype, copy=False)\n",
    "\n",
    "    return y, scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc1b6653-8d4f-4fd6-9464-cb63be103c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6:\n",
    "# Applies a shading correction\n",
    "# It fixes a very common hardware issue in microscopy where the light isn't perfectly even across the camera sensor.\n",
    "# Usually, the center of the image is bright, and the corners are slightly darker (vignetting).\n",
    "# The goal is to mathematically \"flatten\" the background so that a cell in the corner looks just as bright as a cell in the center.\n",
    "# This is done before the deconvolution because the deconvolution algorithms are very sensitive to light levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2545e39-af7b-4b68-a7b2-c4fbd53a63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shading_correct_xy_estimated(\n",
    "    stack: np.ndarray,\n",
    "    sigma_xy: float = 64.0,\n",
    "    z_axis: int = 0,\n",
    "    per_slice: bool = False,\n",
    "    eps: float = 1e-6,\n",
    "    preserve_dtype: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Estimate and correct XY shading/illumination on a 3D microscopy stack.\n",
    "\n",
    "    Model:\n",
    "        corrected = img * mean(field) / field\n",
    "    where `field` is a smooth illumination estimate from a large Gaussian blur.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stack : np.ndarray\n",
    "        3D array (e.g., ZYX).\n",
    "    sigma_xy : float\n",
    "        Gaussian sigma (in pixels) used to estimate illumination field.\n",
    "        Typical: 32256 depending on image size and illumination gradients.\n",
    "    z_axis : int\n",
    "        Axis corresponding to Z (slice dimension).\n",
    "    per_slice : bool\n",
    "        False (recommended): estimate ONE field from the mean projection across Z.\n",
    "        True: estimate a field per slice (can adapt but may cause z-flicker).\n",
    "    eps : float\n",
    "        Small constant to avoid division by zero.\n",
    "    preserve_dtype : bool\n",
    "        If True, output dtype matches input dtype (best-effort).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corrected : np.ndarray\n",
    "        Shading-corrected stack.\n",
    "    field : np.ndarray\n",
    "        The estimated 2D illumination field (Y,X) if per_slice=False,\n",
    "        otherwise None (because it varies per slice).\n",
    "    \"\"\"\n",
    "\n",
    "    if stack.ndim != 3:\n",
    "        raise ValueError(f\"Expected a 3D stack, got shape {stack.shape} (ndim={stack.ndim}).\")\n",
    "\n",
    "    in_dtype = stack.dtype\n",
    "    x = np.moveaxis(stack.astype(np.float32, copy=False), z_axis, 0)  # (Z, Y, X)\n",
    "\n",
    "    if per_slice:\n",
    "        corrected = np.empty_like(x, dtype=np.float32)\n",
    "        for i in range(x.shape[0]):\n",
    "            field_i = gaussian_filter(x[i], sigma=sigma_xy)\n",
    "            field_i = np.maximum(field_i, eps)\n",
    "            norm = float(np.mean(field_i))\n",
    "            corrected[i] = x[i] * (norm / field_i)\n",
    "        field = None\n",
    "    else:\n",
    "        proj = np.mean(x, axis=0)                      # (Y, X)\n",
    "        field = gaussian_filter(proj, sigma=sigma_xy)  # smooth illumination estimate\n",
    "        field = np.maximum(field, eps)\n",
    "        norm = float(np.mean(field))\n",
    "        corrected = x * (norm / field)\n",
    "\n",
    "    corrected = np.moveaxis(corrected, 0, z_axis)\n",
    "\n",
    "    if not preserve_dtype:\n",
    "        return corrected.astype(np.float32, copy=False), field\n",
    "\n",
    "    # Convert back to original dtype\n",
    "    if np.issubdtype(in_dtype, np.integer):\n",
    "        info = np.iinfo(in_dtype)\n",
    "        corrected = np.clip(corrected, info.min, info.max).astype(in_dtype)\n",
    "    else:\n",
    "        corrected = corrected.astype(in_dtype, copy=False)\n",
    "\n",
    "    return corrected, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0542d0e3-16c5-43d7-8581-366502681143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Local Contrast Enhancement (CLAHE), reslicing and image post-processing\n",
    "# CLAHE - Contrast Limited Adaptive Histogram Equalization (CLAHE) - ANNOTATE BETTER\n",
    "# Reslicing - makes the image isotropic. Our original SPIM images are anisotropic with the pixel size in XY (e.g. 0.347x0.347um)\n",
    "# being much smaller than in Z (2um)\n",
    "# Image post-processing - Applies background subtraction and Gaussian smoothing to \"clean up\" the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f40e5f-f540-436a-8547-90a51990018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe_3d_stack(\n",
    "    stack: np.ndarray,\n",
    "    clip_limit: float = 0.01,\n",
    "    kernel_size: Optional[Tuple[int, int]] = None,\n",
    "    axis: int = 0,\n",
    "    preserve_dtype: bool = True,\n",
    "    p_low: float = 0.5,\n",
    "    p_high: float = 99.5,\n",
    "    eps: float = 1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Slice-wise CLAHE for a 3D microscopy stack with robust normalization to [0,1].\n",
    "\n",
    "    p_low/p_high: percentiles for intensity clipping per slice before scaling.\n",
    "    \"\"\"\n",
    "    print(\"Applying clahe_3d_stack\")\n",
    "    from skimage import exposure\n",
    "\n",
    "    if stack.ndim != 3:\n",
    "        raise ValueError(f\"Expected a 3D stack, got shape {stack.shape}\")\n",
    "\n",
    "    in_dtype = stack.dtype\n",
    "    s = np.moveaxis(stack, axis, 0).astype(np.float32, copy=False)  # (S,H,W)\n",
    "\n",
    "    out = np.empty_like(s, dtype=np.float32)\n",
    "\n",
    "    for i in range(s.shape[0]):\n",
    "        img = s[i]\n",
    "\n",
    "        # Robust min/max from percentiles (handles outliers + weird ranges)\n",
    "        lo = np.percentile(img, p_low)\n",
    "        hi = np.percentile(img, p_high)\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if hi <= lo + eps:\n",
    "            out[i] = 0.0\n",
    "            continue\n",
    "\n",
    "        # Clip + scale to [0,1]\n",
    "        img01 = np.clip(img, lo, hi)\n",
    "        img01 = (img01 - lo) / (hi - lo)\n",
    "\n",
    "        # CLAHE expects float in [0,1]\n",
    "        out[i] = exposure.equalize_adapthist(\n",
    "            img01,\n",
    "            kernel_size=kernel_size,\n",
    "            clip_limit=clip_limit,\n",
    "        ).astype(np.float32, copy=False)\n",
    "\n",
    "    out = np.moveaxis(out, 0, axis)\n",
    "\n",
    "    if not preserve_dtype:\n",
    "        return out\n",
    "\n",
    "    # Convert back to original dtype\n",
    "    if np.issubdtype(in_dtype, np.integer):\n",
    "        info = np.iinfo(in_dtype)\n",
    "        out = np.clip(out * info.max, 0, info.max).astype(in_dtype)\n",
    "        return out\n",
    "\n",
    "    return out.astype(in_dtype, copy=False)\n",
    "\n",
    "\n",
    "\n",
    "def reslice(img,position,x_res,z_res):\n",
    "    scale=z_res/x_res\n",
    "    z,y,x=img.shape\n",
    "    new_z = round(z*scale)\n",
    "\n",
    "    #Normalize image  to [0, 1] before extrapolating\n",
    "    img_max = np.amax(img).astype(np.float32)\n",
    "    img_normalized = img.astype(np.float32) / img_max\n",
    "\n",
    "    if position=='xz':\n",
    "        reslice_img=np.transpose(img_normalized,[1,0,2])\n",
    "        scale_img=np.zeros((y,new_z,x),dtype=np.float32)\n",
    "        for i in range(y):\n",
    "            scale_img[i] = resize(reslice_img[i], (new_z,x), order=3,anti_aliasing=True)\n",
    "\n",
    "    elif position=='yz':\n",
    "        reslice_img=np.transpose(img_normalized,[2,0,1])\n",
    "        scale_img = np.zeros((x,new_z,y), dtype=np.float32)\n",
    "        for i in range(x):\n",
    "            scale_img[i] = resize(reslice_img[i], (new_z,y), order=3,anti_aliasing=True)\n",
    "\n",
    "    elif position=='xy':\n",
    "        reslice_img=np.transpose(img_normalized,[1,0,2])\n",
    "        scale_img=np.zeros((y,new_z,x),dtype=np.float32)\n",
    "        for i in range(y):\n",
    "            scale_img[i] = resize(reslice_img[i], (new_z,x), order=3,anti_aliasing=True)\n",
    "        scale_img=np.transpose(scale_img,[1,0,2])\n",
    "\n",
    "    # Re scale intensities\n",
    "    scale_img[scale_img < 0] = 0\n",
    "    scale_img[scale_img > 1] = 1\n",
    "    rescaled_img = (scale_img * img_max).astype(np.uint16)\n",
    "\n",
    "\n",
    "    return rescaled_img\n",
    "\n",
    "\n",
    "\n",
    "def image_postprocessing(img, resolution_px, resolution_pz, noise_lvl, sigma):\n",
    "    \"\"\"\n",
    "    Post-processes the image by removing noise and applying smoothing, with a progress bar.\n",
    "    \"\"\"\n",
    "    #print(\"image_postprocessing : image size\", img.shape)\n",
    "\n",
    "    steps = []\n",
    "    if resolution_px > 0:\n",
    "        steps.append(\"Remove Background/Noise\")\n",
    "\n",
    "    if resolution_pz > 0:\n",
    "        steps.append(\"Remove Background/Noise z\")\n",
    "\n",
    "    if sigma > 0:\n",
    "        steps.append(\"Gaussian Smoothing\")\n",
    "\n",
    "    pbar = tqdm(total=len(steps), desc=\"Postprocessing Image\", unit=\"step\")\n",
    "\n",
    "    # Step 1: Remove background and noise\n",
    "    if resolution_px > 0:\n",
    "        img = WBNS_image(img, resolution_px, noise_lvl)\n",
    "        pbar.update(1)\n",
    "\n",
    "    if resolution_pz > 0:\n",
    "        img_xz = np.transpose(img,[1,0,2])\n",
    "        img_xz = WBNS_image(img_xz, resolution_pz, 0)\n",
    "        img = np.transpose(img_xz,[1,0,2])\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Step 2: Smoothing\n",
    "    if sigma > 0:\n",
    "        img = ndi.gaussian_filter(img, sigma)\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    return img\n",
    "\n",
    "\n",
    "def getNormalizationThresholds(img, percentiles):\n",
    "\n",
    "    # flaten array\n",
    "    if np.ndim(img) > 1:\n",
    "        img = img.flatten()\n",
    "\n",
    "    # get background thres\n",
    "    low_thres = np.percentile(img,percentiles[0])\n",
    "    # get foreground thres\n",
    "    high_thres = np.percentile(img,percentiles[1])\n",
    "\n",
    "\n",
    "    return low_thres, high_thres\n",
    "\n",
    "def remove_outliers_image(img, low_thres, high_thres,print_res=False):\n",
    "\n",
    "    if print_res == True:\n",
    "        img_min = np.amin(img)\n",
    "        img_max = np.amax(img)\n",
    "\n",
    "    # Set the values in the image\n",
    "    img[img > high_thres] = high_thres\n",
    "    img = img - low_thres\n",
    "    img[img < 0] = 0\n",
    "\n",
    "    if print_res == True:\n",
    "        newimg_min = np.amin(img)\n",
    "        newimg_max = np.amax(img)\n",
    "        print('Cropping Intensity from (%d , %d) to  (%d, %d) ' % (img_min, img_max, newimg_min, newimg_max))\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "208ee9ca-2eee-4b2d-a419-71d34cbc6892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: configuration and paths\n",
    "# This is the section where we change the input and output folders and the different processing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b22c9-9693-4b1f-aea3-2bffda9fb2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -image dimension from : (65, 256, 256) to (65, 256, 256)\n",
      "\n",
      "Importing : C:\\Users\\guilherme.bastosvent\\Downloads\\nuclear_selection_18x.tif\n",
      "- shape: (7, 51, 51) dtype: uint16\n",
      "- estimated size (GB): 3.3913180232048035e-05\n",
      "- voxel sizes (um): [0.34700004580400606, 0.34700004580400606, 2.0]\n",
      "- image dimension : (7, 51, 51), scaling 1.0\n",
      "- image dimension from : (7, 51, 51) to (7, 51, 51), scaling 1.0\n",
      "shading_correct_xy_estimated\n",
      "z_intensity_correction\n",
      "     -image dimension from : (7, 51, 51) to (40, 51, 51) after isotropic interpolation\n",
      "     -z-space from : 2.0 to 0.35\n",
      "BG suntraction : 28,  28\n",
      "     -Intensity Norm  from (2145 , 6571) to  (0, 65535) \n",
      "     -size(GB) :  0.005123764276504517\n",
      "     -Intensity Norm  from (0 , 85425) to  (0, 65534) \n",
      "     img_xz -size(GB) :  0.005123764276504517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Postprocessing Image:   0%|          | 0/3 [00:00<?, ?step/s]c:\\Users\\guilherme.bastosvent\\AppData\\Local\\miniforge3\\envs\\microscopy_env\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1105: UserWarning: On Windows, max_workers cannot exceed 60 due to limitations of the operating system.\n",
      "  warnings.warn(\n",
      "Postprocessing Image: 100%|██████████| 3/3 [00:09<00:00,  3.14s/step]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying clahe_3d_stack\n",
      "     -Intensity Norm  from (0 , 1) to  (0, 65535) \n",
      "Elapsed Time: 26.5664 seconds, image nuclear_selection_18x.tif\n",
      "\n",
      "Importing : C:\\Users\\guilherme.bastosvent\\Downloads\\t0120_Channel 2.tif\n",
      "- shape: (80, 2304, 2304) dtype: uint16\n",
      "- estimated size (GB): 0.791015625\n",
      "- voxel sizes (um): [0.34700004580400606, 0.34700004580400606, 2.0]\n",
      "- image dimension : (80, 2304, 2304), scaling 1.0\n",
      "- image dimension from : (80, 2304, 2304) to (80, 2304, 2304), scaling 1.0\n",
      "shading_correct_xy_estimated\n",
      "z_intensity_correction\n",
      "     -image dimension from : (80, 2304, 2304) to (461, 2304, 2304) after isotropic interpolation\n",
      "     -z-space from : 2.0 to 0.3470715835140998\n",
      "BG suntraction : 28,  28\n",
      "     -Intensity Norm  from (43 , 52080) to  (0, 65535) \n",
      "     -size(GB) :  10.966873168945312\n"
     ]
    }
   ],
   "source": [
    "# Utility: Print system resource usage\n",
    "import subprocess\n",
    "import psutil\n",
    "\n",
    "def print_resource_usage():\n",
    "    vm = psutil.virtual_memory()\n",
    "    print(f\"    [Resource] CPU usage: {psutil.cpu_percent()}% | RAM used: {vm.used / (1024**3):.2f} GB / {vm.total / (1024**3):.2f} GB\")\n",
    "    # Try to print GPU usage if nvidia-smi is available\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=utilization.gpu,memory.used,memory.total', '--format=csv,noheader,nounits'],\n",
    "                               stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True)\n",
    "        for i, line in enumerate(result.stdout.strip().split('\\n')):\n",
    "            util, mem_used, mem_total = line.split(',')\n",
    "            print(f\"    [GPU {i}] Utilization: {util.strip()}% | Memory: {mem_used.strip()} / {mem_total.strip()} MB\")\n",
    "    except Exception:\n",
    "        print(\"    [Resource] GPU info: nvidia-smi not available or no GPU detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e21807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Predictions for a folder\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "# Define paths\n",
    "\n",
    "# Images\n",
    "img_src_path = r'C:\\Users\\andres.ortiz\\Desktop\\Projects\\spim_preprocessing\\data\\input_low-res'\n",
    "\n",
    "# output dir\n",
    "outdir = r'C:\\Users\\andres.ortiz\\Desktop\\Projects\\spim_preprocessing'\n",
    "#outdir = r'/medicina/hmorales/projects/ImagePreprocessing/results/'\n",
    "\n",
    "# Image data\n",
    "image_scaling  = 1.0 # number > 0\n",
    "xy_pixel = 0 # different than 0 to force pixel size\n",
    "z_pixel = 0 # different than 0 to force pixel size\n",
    "\n",
    "apply_clahe = True\n",
    "apply_z_intensity_correction = True\n",
    "apply_shading_correct = True\n",
    "\n",
    "# normal deconvolution\n",
    "psf_path = r'C:\\Users\\andres.ortiz\\Desktop\\Projects\\spim_preprocessing\\data\\PSF_models\\low_res\\PSF_bw_settings_1-low_res.tif'\n",
    "padding = 32\n",
    "Niter = 3\n",
    "Niterz = 3\n",
    "\n",
    "# Image Normalization\n",
    "min_v = 0\n",
    "max_v = 65535\n",
    "percentiles_source = (40, 99.99)  #99.9995 For Nuclei, 99.999 For Membranes\n",
    "\n",
    "# BG subtraction\n",
    "resolution_px0 = 10 # FWHM of the PSF in um\n",
    "resolution_pz0 = 10\n",
    "noise_lvl = 2\n",
    "\n",
    "# post processing\n",
    "sigma = 1.0\n",
    "\n",
    "\n",
    "# Create output folder\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "\n",
    "if xy_pixel > 0:\n",
    "  tempScale = z_pixel / xy_pixel\n",
    "else:\n",
    "  tempScale = 0\n",
    "\n",
    "\n",
    "if Niter > 0:\n",
    "    # Open PSF and Prepare PSF\n",
    "    psf = tifffile.imread(psf_path)\n",
    "    psf_shape = psf.shape\n",
    "    if image_scaling > 0:\n",
    "        psf = rescale(psf, (image_scaling, image_scaling, image_scaling), order=3, preserve_range=True, anti_aliasing=True)\n",
    "        print(f\"     -image dimension from : {psf_shape} to {psf.shape}\")\n",
    "    psf_f = psf.astype(np.float32)\n",
    "    psf = psf_f/psf_f.sum()\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "# Get all tif images in the folder\n",
    "image_names = [f for f in os.listdir(img_src_path) if f.lower().endswith(('.tif', '.tiff', '.nd2'))]\n",
    "\n",
    "# Calculate for each model\n",
    "for i, image_name in enumerate(image_names):\n",
    "    print(f\"\\n[Step {i+1}/{len(image_names)}] Starting processing for: {image_name}\")\n",
    "    start_time = time.time()  # Record the start time\n",
    "    print_resource_usage()\n",
    "\n",
    "    img_path = os.path.join(img_src_path, image_name)\n",
    "    print(f\"  Importing : {img_path}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Load image depending on format\n",
    "    # ---------------------------------------------------------\n",
    "    ext = os.path.splitext(image_name)[1].lower()\n",
    "\n",
    "    if ext in ['.tif', '.tiff']:\n",
    "        print(\"  Loading TIFF image...\")\n",
    "        img  =  tifffile.imread(img_path).astype(np.uint16)\n",
    "        voxel_size = read_tiff_voxel_size(img_path)\n",
    "    elif ext == '.nd2':\n",
    "        print(\"  Loading ND2 image...\")\n",
    "        img = pims.open(img_path)\n",
    "        voxel_size = read_nd2_voxel_size(img)\n",
    "        img = np.array(img, dtype=np.uint16, copy=False)\n",
    "    print(\"  - shape:\", np.array(img).shape, \"dtype:\", img.dtype)\n",
    "    print(\"  - estimated size (GB):\", np.array(img).nbytes / (1024**3))\n",
    "    print_resource_usage()\n",
    "\n",
    "    physical_pixel_sizeX, physical_pixel_sizeY, physical_pixel_sizeZ = voxel_size\n",
    "\n",
    "    if tempScale > 0:\n",
    "        scale = tempScale\n",
    "        physical_pixel_sizeX = xy_pixel\n",
    "        physical_pixel_sizeZ = z_pixel\n",
    "\n",
    "    print(\"  - voxel sizes (um):\", voxel_size)\n",
    "\n",
    "    if image_scaling > 0:\n",
    "        img_shape = img.shape\n",
    "        print(f\"  - image dimension : {img.shape}, scaling {image_scaling}\")\n",
    "        img = rescale(img, (1.0, image_scaling, image_scaling), order=3, preserve_range=True, anti_aliasing=True)\n",
    "        physical_pixel_sizeX /= image_scaling\n",
    "        print(f\"  - image dimension from : {img_shape} to {img.shape}, scaling {image_scaling}\")\n",
    "        img_shape = img.shape\n",
    "    print_resource_usage()\n",
    "\n",
    "    scale = physical_pixel_sizeX / physical_pixel_sizeZ\n",
    "\n",
    "    # pre-processing\n",
    "    if apply_shading_correct == True:\n",
    "        print(\"[Check-in] Running shading_correct_xy_estimated...\")\n",
    "        img, field = shading_correct_xy_estimated(img, sigma_xy=96, z_axis=0, per_slice=False)\n",
    "        print_resource_usage()\n",
    "\n",
    "    if apply_z_intensity_correction == True:\n",
    "        print(\"[Check-in] Running z_intensity_correction...\")\n",
    "        img, scales = z_intensity_correction(img, z_axis=0, method=\"p95\", smooth_window=11)\n",
    "        print_resource_usage()\n",
    "\n",
    "    # Make image isotropic\n",
    "    if abs(1.0-scale) > 1e-4 :\n",
    "        print(\"[Check-in] Reslicing to isotropic...\")\n",
    "        img = reslice(img,'xy',physical_pixel_sizeX,physical_pixel_sizeZ)\n",
    "    img = img.astype(np.float32)\n",
    "    new_img_shape = img.shape\n",
    "    new_physical_pixel_sizeZ = img_shape[0] * physical_pixel_sizeZ / new_img_shape[0]\n",
    "    print(f\"  - image dimension from : {img_shape} to {new_img_shape} after isotropic interpolation\")\n",
    "    print(f\"  - z-space from : {physical_pixel_sizeZ} to {new_physical_pixel_sizeZ}\")\n",
    "    physical_pixel_sizeZ = new_physical_pixel_sizeZ\n",
    "    pixel_size_X = physical_pixel_sizeX\n",
    "    print_resource_usage()\n",
    "\n",
    "    # Recalculate resolution for BG subtraction\n",
    "    resolution_px = int(resolution_px0 / new_physical_pixel_sizeZ)\n",
    "    resolution_pz = int(resolution_pz0 / new_physical_pixel_sizeZ)\n",
    "    print(f\"  BG subtraction : {resolution_px},  {resolution_pz}\")\n",
    "\n",
    "    # Deconvolution\n",
    "    if Niter > 0:\n",
    "        print(\"[Check-in] Running 3D deconvolution...\")\n",
    "        img = image_scaling_intens(img, min_v, max_v, True)\n",
    "        img = np.pad(img, padding, mode='reflect')\n",
    "        imgSizeGB = img.nbytes / (1024 ** 3)\n",
    "        print('    -size(GB) : ', imgSizeGB)\n",
    "        print_resource_usage()\n",
    "        res_gpu = rl.doRLDeconvolutionFromNpArrays(img, psf, niter=Niter,resAsUint8=False)\n",
    "        img = res_gpu[padding:-padding, padding:-padding, padding:-padding]\n",
    "        print_resource_usage()\n",
    "\n",
    "    if Niterz > 0:\n",
    "        print(\"[Check-in] Running 2D (XZ) deconvolution...\")\n",
    "        img = image_scaling_intens(img, min_v, max_v, True)\n",
    "        img_xz = np.transpose(img,[1,0,2])\n",
    "        psf_xz = np.transpose(psf,[1,0,2])\n",
    "        img_xz = np.pad(img_xz, padding, mode='reflect')\n",
    "        imgSizeGB = img_xz.nbytes / (1024 ** 3)\n",
    "        print('    img_xz -size(GB) : ', imgSizeGB)\n",
    "        print_resource_usage()\n",
    "        res_gpu = rl.doRLDeconvolutionFromNpArrays(img_xz, psf_xz, niter=Niter,resAsUint8=False)\n",
    "        img_xz = res_gpu[padding:-padding, padding:-padding, padding:-padding]\n",
    "        img = np.transpose(img_xz,[1,0,2])\n",
    "        psf = np.transpose(psf_xz,[1,0,2])\n",
    "        print_resource_usage()\n",
    "\n",
    "    print(\"[Check-in] Running post-processing...\")\n",
    "    img = image_postprocessing(img, resolution_px, resolution_pz, noise_lvl, sigma)\n",
    "    print_resource_usage()\n",
    "\n",
    "    if apply_clahe == True:\n",
    "        print(\"[Check-in] Applying CLAHE...\")\n",
    "        img_xz = np.transpose(img,[1,0,2])\n",
    "        img_xz= clahe_3d_stack(img_xz, clip_limit=0.01, kernel_size=(64, 64), axis=0)\n",
    "        img = np.transpose(img_xz,[1,0,2])\n",
    "        print_resource_usage()\n",
    "\n",
    "    # Image Normalization\n",
    "    if percentiles_source[0] > 0 or percentiles_source[1] < 100:\n",
    "        print(\"[Check-in] Removing outliers and normalizing intensities...\")\n",
    "        low_thres, high_thres = getNormalizationThresholds(img, percentiles_source)\n",
    "        img = remove_outliers_image(img, low_thres, high_thres)\n",
    "        print_resource_usage()\n",
    "\n",
    "    print(\"[Check-in] Final intensity scaling and saving...\")\n",
    "    img = image_scaling_intens(img, min_v, max_v, True)\n",
    "    img = img.astype(np.uint16)\n",
    "\n",
    "    # Save images\n",
    "    base_name = os.path.splitext(image_name)[0]\n",
    "    image_out = f\"{base_name}_{100*image_scaling}.tif\"\n",
    "    img_out = os.path.join(outdir, image_out)\n",
    "    tifffile.imwrite(img_out,img)\n",
    "    print(f\"  Saved processed image to: {img_out}\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"[Done] Elapsed Time: {elapsed_time:.4f} seconds, image {image_name}\")\n",
    "    print_resource_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microscopy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
